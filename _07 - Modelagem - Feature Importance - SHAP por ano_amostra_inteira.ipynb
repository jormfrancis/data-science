{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.ticker as mtick\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1529177, 85)\n"
     ]
    }
   ],
   "source": [
    "# Import final data base de inscritos presentes em todas as provas sem missing ~32 MM\n",
    "df = pd.read_csv('df_basepronta2.csv', sep = ';')\n",
    "\n",
    "print(df.shape)\n",
    "#(1529177, 57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Nota Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   74.993608\n",
       "1   25.006392\n",
       "Name: target_geral, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target: variavel resposta dependente (desempenho em matematica) de acordo com um certo ponto de corte para cada ano (threshold):\n",
    "threshold = .75\n",
    "\n",
    "df_desemp = df.groupby('NU_ANO')['NU_MEDIA'].quantile(threshold).reset_index(name = 'desemp_geral')\n",
    "\n",
    "df = df.merge(df_desemp, on = 'NU_ANO', how = 'left')\n",
    "\n",
    "df['target_geral'] = np.where(df.NU_MEDIA < df.desemp_geral, 0, 1)\n",
    "\n",
    "df['target_geral'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base e variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1529177, 87)\n"
     ]
    }
   ],
   "source": [
    "df_models = df.copy()\n",
    "print(df_models.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_y = ['target_geral']\n",
    "\n",
    "keep_X_features = [\n",
    "'FEMININO'\n",
    ",'sóI'\n",
    ",'sóC'\n",
    ",'IeC'\n",
    ",'Branca'\n",
    ",'Parda'\n",
    ",'Raca_outra'\n",
    ",'CentroOeste'\n",
    ",'Nordeste'\n",
    ",'Norte'\n",
    ",'Sudeste'\n",
    ",'Sul'\n",
    ",'escpartic_outra'\n",
    ",'escpubl'\n",
    ",'Mae_ESup_mais'\n",
    ",'Mae_Ens_fundamental2'\n",
    ",'Mae_Ens_medio3'\n",
    ",'Mae_desc_nada0'\n",
    ",'Mae_fund_incompl1'\n",
    ",'Pai_ESup_mais'\n",
    ",'Pai_Ens_fundamental2'\n",
    ",'Pai_Ens_medio3'\n",
    ",'Pai_desc_nada0'\n",
    ",'Pai_fund_incompl1'\n",
    ",'tamfam3peq'\n",
    ",'tamfam5med'\n",
    ",'tamfam6gde'\n",
    ",'infra_basicacompleta'\n",
    ",'infra_basicaincompleta'\n",
    ",'renda_0e1'\n",
    ",'renda_15'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Um modelo por ano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controlado por faixa de renda (classe = baixa renda) e ocupação da mãe (grupos 1, 2 e 3) e ocupação do pai (grupos 1, 2 e 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificar o feature importance de cada ano dos modelos XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_ano = {}\n",
    "X =             {}\n",
    "y =             {}\n",
    "X_train =       {}\n",
    "X_test =        {}\n",
    "y_train =       {}\n",
    "y_test =        {}\n",
    "\n",
    "\n",
    "model_xg = {}\n",
    "auc_xg_train = {}\n",
    "fpr_xg_train = {}\n",
    "tpr_xg_train = {}\n",
    "thresholds_xg_train = {}\n",
    "\n",
    "auc_xg_test = {}\n",
    "fpr_xg_test = {}\n",
    "tpr_xg_test = {}\n",
    "thresholds_xg_test = {}\n",
    "\n",
    "X_testGra = {}\n",
    "X_testPeq = {}\n",
    "\n",
    "columns = ['model','ano','feature','score']\n",
    "rows_anos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X[ 2015 ]..: (195417, 31)\n",
      "Qtde treino......: (97708, 31)\n",
      "Qtde teste.......: (97709, 31)\n",
      "Ano 2015 :\n",
      "    Fit...\n",
      "    Apply...\n",
      "    Compare...\n",
      "    AUCs:\n",
      "        Treino: 0.7166232217059885\n",
      "        Teste: 0.6709180274181115\n",
      "    Feature importance...\n",
      "    SHAP Values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|=================== | 90524/97708 [07:09<00:34]       "
     ]
    }
   ],
   "source": [
    "### Para cada ano, temos um conjunto de dados:\n",
    "anos = df_models.NU_ANO.unique()\n",
    "\n",
    "for i, ano in enumerate(anos):\n",
    "\n",
    "    # df\n",
    "    df_models_ano[i] = df_models[df_models['NU_ANO'] == ano]\n",
    "\n",
    "    # Features\n",
    "    X[i] = df_models[df_models['NU_ANO'] == ano][keep_X_features]\n",
    "    print('Shape X[',ano,']..:', X[i].shape)\n",
    "\n",
    "    # Target\n",
    "    y[i] = df_models[df_models['NU_ANO'] == ano][keep_y]\n",
    "\n",
    "    # Train Test Split\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(X[i], y[i], test_size = 0.5, random_state = 42)\n",
    "\n",
    "    print('Qtde treino......:', X_train[i].shape)\n",
    "    print('Qtde teste.......:', X_test[i].shape)\n",
    "    \n",
    "    print('Ano', ano, ':')\n",
    "    # Fit model\n",
    "    print('    Fit...')\n",
    "    model_xg[i] = XGBClassifier().fit(X_train[i], y_train[i].target_geral)\n",
    "    \n",
    "    # Apply model\n",
    "    print('    Apply...')\n",
    "    df_models_ano[i]['xg_pred'] = model_xg[i].predict_proba(df_models_ano[i][keep_X_features])[:, 1]\n",
    "    \n",
    "    # Compare\n",
    "    print('    Compare...')\n",
    "    y_train[i]['xg_pred'] = model_xg[i].predict_proba(X_train[i])[:, 1]\n",
    "    y_test[i]['xg_pred'] = model_xg[i].predict_proba(X_test[i])[:, 1]\n",
    "        \n",
    "    # AUC pro treino e teste\n",
    "    print('    AUCs:')\n",
    "    # treino\n",
    "    auc_xg_train[i] = roc_auc_score(y_train[i].target_geral, y_train[i].xg_pred)\n",
    "    fpr_xg_train[i], tpr_xg_train[i], thresholds_xg_train[i] = roc_curve(y_train[i].target_geral, y_train[i].xg_pred)\n",
    "    print('        Treino:', auc_xg_train[i])\n",
    "    \n",
    "    # teste\n",
    "    auc_xg_test[i] = roc_auc_score(y_test[i].target_geral, y_test[i].xg_pred)\n",
    "    fpr_xg_test[i], tpr_xg_test[i], thresholds_xg_test[i] = roc_curve(y_test[i].target_geral, y_test[i].xg_pred)\n",
    "    print('        Teste:', auc_xg_test[i])\n",
    "    \n",
    "    # Feature importance\n",
    "    print('    Feature importance...')\n",
    "    importance = model_xg[i].feature_importances_\n",
    "    for j, v in enumerate(importance):\n",
    "        row = ['xg', ano, keep_X_features[j], v]\n",
    "        rows_anos.append(row)\n",
    "\n",
    "    # SHAP Values\n",
    "    print('    SHAP Values...')\n",
    "    explainer = shap.Explainer(model_xg[i], X_train[i])\n",
    "    shap_values = explainer(X_train[i])\n",
    "    shap.summary_plot(shap_values, X_train[i], show = False)\n",
    "    plt.title(f'SHAP Summary Plot for Model XGBoost {ano}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP com uma amostra pequena de dados para rodar mais rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ano in enumerate(anos):\n",
    "    \n",
    "    print('Ano', ano, ':')\n",
    "    # Fit model\n",
    "    print('    Fit...')\n",
    "    model_xg[i] = XGBClassifier().fit(X_train[i], y_train[i].target_geral)\n",
    "    \n",
    "    # Apply model\n",
    "    print('    Apply...')\n",
    "    df_models_ano[i]['xg_pred'] = model_xg[i].predict_proba(df_models_ano[i][keep_X_features])[:, 1]\n",
    "    \n",
    "    # Compare\n",
    "    print('    Compare...')\n",
    "    y_train[i]['xg_pred'] = model_xg[i].predict_proba(X_train[i])[:, 1]\n",
    "    y_test[i]['xg_pred'] = model_xg[i].predict_proba(X_test[i])[:, 1]\n",
    "        \n",
    "    # AUC pro treino e teste\n",
    "    print('    AUCs:')\n",
    "    # treino\n",
    "    auc_xg_train[i] = roc_auc_score(y_train[i].target_geral, y_train[i].xg_pred)\n",
    "    fpr_xg_train[i], tpr_xg_train[i], thresholds_xg_train[i] = roc_curve(y_train[i].target_geral, y_train[i].xg_pred)\n",
    "    print('        Treino:', auc_xg_train[i])\n",
    "    \n",
    "    # teste\n",
    "    auc_xg_test[i] = roc_auc_score(y_test[i].target_geral, y_test[i].xg_pred)\n",
    "    fpr_xg_test[i], tpr_xg_test[i], thresholds_xg_test[i] = roc_curve(y_test[i].target_geral, y_test[i].xg_pred)\n",
    "    print('        Teste:', auc_xg_test[i])\n",
    "    \n",
    "    # Feature importance\n",
    "    print('    Feature importance...')\n",
    "    importance = model_xg[i].feature_importances_\n",
    "    for j, v in enumerate(importance):\n",
    "        row = ['xg', ano, keep_X_features[j], v]\n",
    "        rows_anos.append(row)\n",
    "\n",
    "    # SHAP Values\n",
    "    print('    SHAP Values...')\n",
    "\n",
    "    X_testGra[i], X_testPeq[i] = train_test_split(X_test[i], test_size = 0.1, random_state = 42)\n",
    "    \n",
    "    explainer = shap.Explainer(model_xg[i], X_testPeq[i])\n",
    "    shap_values = explainer(X_testPeq[i])\n",
    "    shap.summary_plot(shap_values, X_testPeq[i], show = False)\n",
    "    plt.title(f'SHAP Summary Plot for Model XGBoost {ano}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impor_anos = pd.DataFrame(rows_anos, columns=columns)\n",
    "\n",
    "# importância ordenada pelo melhor modelo na validação (xg)\n",
    "imp_anos = df_feat_impor_anos.pivot(index = 'feature', columns = 'ano', values = 'score').sort_values(by=[2021], ascending = False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,16))\n",
    "sns.heatmap(imp_anos, cmap = 'Blues', annot=True, ax = ax)\n",
    "ax.xaxis.tick_top() # x axis on top\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
